\documentclass[11pt,oneside]{article}
\input{coursHeadings}
\input{programHeadings}
\usepackage[%
    pdftitle={Complexité des algorithmes},
    pdfauthor={Xavier Pessoles},
    colorlinks=true,
    linkcolor=blue,
    citecolor=magenta]{hyperref}

\usepackage{pifont}


% \makeatletter \let\ps@plain\ps@empty \makeatother
%% DEBUT DU DOCUMENT
%% =================
\sloppy
\hyphenpenalty 10000

\newcommand{\Pointilles}[1][3]{%
\multido{}{#1}{\makebox[\linewidth]{\dotfill}\\[\parskip]
}}


\colorlet{shadecolor}{orange!15}

\newtheorem{theorem}{Theorem}


\begin{document}


\newboolean{prof}
\setboolean{prof}{true}
%------------- En tetes et Pieds de Pages ------------
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}

\fancyhead{}
\fancyhead[L]{%
\noindent\noindent\begin{minipage}[c]{2.6cm}
%Lycée Rouvière PTSI
\includegraphics[width=2.5cm]{png/logo_upsti.png}%
\end{minipage}
}

\fancyhead[C]{\rule{12cm}{.5pt}}

\fancyhead[R]{%
\noindent\begin{minipage}[c]{3cm}
\begin{flushright}
\footnotesize{\textit{\textsf{Informatique}}}%
\end{flushright}
\end{minipage}
}

\renewcommand{\footrulewidth}{0.2pt}

\fancyfoot[C]{\footnotesize{\bfseries \thepage}}
\fancyfoot[L]{%
\begin{minipage}[c]{.2\linewidth}
\footnotesize{\textsl{Xavier Pessoles}}\\
\footnotesize{\textsl{UPSTI}}
\end{minipage}
\begin{minipage}[c]{.15\linewidth}
\includegraphics[width=2cm]{png/logoCC.png}
\end{minipage}}

\ifthenelse{\boolean{prof}}{%
\fancyfoot[R]{\footnotesize{Cours -- CI 2 : Algorithmique \& Programmation}}
}{%
%\fancyfoot[R]{\footnotesize{Cours -- CI 6 : PPM}}
}


\begin{center}
 \huge\textsc{CI 2 -- Algorithmique et Programmation}

% \large\textsc{Introduction à la programmation}
\end{center}

\begin{center}
 \LARGE\textsc{Chapitre 3 -- Performance des algorithmes}
\end{center}

\vspace{.5cm}



\begin{minipage}[c]{.3\linewidth}
\begin{center}

\end{center}
\end{minipage} \hfill
\begin{minipage}[c]{.3\linewidth}
\begin{center}

\end{center}
\end{minipage} \hfill
\begin{minipage}[c]{.3\linewidth}
\begin{center}

\end{center}
\end{minipage}

\vspace{.5cm}


%\begin{center}
%\includegraphics[width=.9\textwidth]{png/cyclev.png}

%\textit{Cycle de conception d'un produit}
%\end{center}

%\begin{prob}
%\textsc{Problématique :}

%En phase d'avant conception d'un produit, quels sont les critères qui vont permettre de choisir les matériaux à utiliser ?
%\end{prob}



\begin{savoir}
\textsc{Savoirs :}
\begin{itemize}
\item justifier qu'une itération (ou boucle) produit l'effet attendu au moyen d'un invariant;
\item démontrer qu'une boucle se termine effectivement;
\item s'interroger sur l'efficacité algorithmique temporelle.
\end{itemize}
\end{savoir}
 

\setlength{\parskip}{0ex plus 0.2ex minus 0ex}
 \renewcommand{\contentsname}{}
 \renewcommand{\baselinestretch}{1}

\tableofcontents

 \renewcommand{\baselinestretch}{1.2}
\setlength{\parskip}{2ex plus 0.5ex minus 0.2ex}

% \vspace{1cm}
\textit{Ce document évolue. Merci de signaler toutes erreurs ou coquilles.}



\section{Invariance de boucle}
\subsection{Problématique}
Lors de la réalisation d'un algorithme, il est nécessaire
\begin{itemize} 
\item de vérifier que celui-ci permet bien de répondre au problème initial;
\item de s'assurer que celui-ci se termine sans quoi le résultat du problème ne sera jamais délivré à l'utilisateur.
\end{itemize}

On s'intéresse ici uniquement aux structures itératives. (Les structures récursives seront traitées en seconde année.)

\begin{defi}
\textbf{Invariant de boucle \cite{denis}}

Un invariant de boucle est une propriété ou une formule logique, 
\begin{itemize}
\item qui est vérifiée après la phase d'initialisation;
\item qui reste vraie après l'exécution d'une itération;
\item et qui, conjointement à la condition d'arrêt, permet de montrer que le résultat attendu et bien le résultat calculé. 
\end{itemize}
\end{defi}


\begin{methode}
\cite{soyeur}
\begin{enumerate}
\item Définir les préconditions (état des variables avant d’entrer dans la boucle)
\item Définir un invariant de boucle
\item Prouver l’invariant (correspond à $\mathcal{P}(n) \Longleftarrow \mathcal{P}(n + 1)$).
\item Montrer la terminaison du programme.
\item Condition de sortie de boucle + invariant de boucle $\Longleftarrow$ postcondition.
\end{enumerate}
\end{methode}

\subsection{Exemple -- L'algorithme d'Euclide.}


Cet algorithme permet de calculer le PGCD de deux nombres entiers. Il se base sur le fait que si $a$ et $b$ sont deux entiers naturels non nuls, $pgcd(a,b)=pgcd(b, a \text{mod} b)$. 


\begin{pseudo}
\begin{algorithm}[H]
\KwData{$a,b \in\mathbb{N}^*$, $a<b$}
$x\gets a$\\
$y\gets b$\\
\Tq{$y\neq 0$}{
$r\gets$ reste de la division euclidienne de $x$ par $y$\\
$x\gets y$\\
$y\gets r$
}

\end{algorithm}
\end{pseudo}

\begin{exemple}
Calculons le PGCD de 240 et 64 :
\begin{eqnarray*}
240 = 3\cdot 64 + 48 \\
64 = 1\cdot 48 + 16 \\
48 = 3\cdot 16 + 0 \\
\end{eqnarray*}

$pgcd(240,64)$ est le dernier reste non nul à savoir 16.

\end{exemple}

\begin{demo}
Soient $a$ et $b$, tels que $(a;b)\in \mathbb{N}^*$ tels que $a > b$. Soient $(q;r)\in \mathbb{N}$ tels que $a=b\cdot q+r$. Avec $r$ le reste de la division euclidienne de $a$ par $b$ et $q$ le quotient.

\textbf{Montrons que $PGCD(a,b)=PGCD(b,r)$.}

Soit $d\in\mathbb{N}$ un diviseur commun de $a$ et $b$. Dans ce cas, $d$ divise $a-b\cdot q$; donc $d$ divise $r$.

En conclusion, si $d$ divise $a$ et $b$ alors $PGCD(a,b)=PGCD(b,r)$.

Réciproquement, soit $d\in\mathbb{N}$ un diviseur commun de $b$ et $r$. Dans ce cas, $d$ divise $b\cdot q+r$; donc $d$ divise $a$.

En conclusion, si $d$ divise $b$ et $r$ alors $PGCD(a,b)=PGCD(b,r)$.

On a donc $PGCD(a,b)=PGCD(b,r)$.

\end{demo}


\begin{demo}
\textbf{Preuve par invariant de boucle}

Montrons que la propriété  $x=y\cdot q+r$ est un invariant de boucle :
\begin{itemize}
\item au premier incrément, $r$ étant le reste de la division euclidienne de $x$ par $y$, on a donc bien  $x=y\cdot q+r$;
\item à l'incrément suivant, $x'\gets y$ et $y' \gets r$. On peut donc trouver $r'$ tel que $x'=y'\cdot q'+r'$. La propriété reste donc vraie;
\item par définition de la division euclidienne, $r<y$; donc à chaque incrément la quantité $y$ diminue. La boucle pourra donc s'arrêter.
\end{itemize}
\end{demo}

%\subsection{Crible d'Ératosthène}
%Cet algorithme permet de déterminer les nombre premiers d'une liste de $n$ nombre entiers.
%
%\begin{pseudo}
%\begin{algorithm}[H]
%\KwData{$n \in\mathbb{N}^*$}
%$tab$ contient la liste des $n$ entiers\\
%\For{$i=1$ \KwTo $n$}{
%\For{$j=n$ \KwTo $i$}{
%\If{$tab[j]$ modulo $tab[i] =0$}{
%Supprimer $tab[j]$
%}}
%}
%
%\end{algorithm}
%\end{pseudo}


\section{Complexité des algorithmes}

\subsection{Présentation}
Il existe souvent plusieurs façons de programmer un algorithme. Si le nombre d'opérations à effectuer est peu important et les données d'entrée de l'algorithme sont de faibles tailles, le choix de la solution importe peu. En revanche, lorsque le nombre d'opérations et la taille des données d'entrée deviennent importants, deux paramètres deviennent déterminants : le temps d'exécution et l'occupation mémoire. 


\begin{defi}
\textbf{Complexité en temps}

La complexité en temps donne le nombre d'opérations effectuées lors de l'exécution d'un programme. On appelle $C_o$ le coût en temps d'une opération $o$.

\textbf{Complexité en mémoire (ou en espace)}

La complexité en mémoire donne le nombre d'emplacements mémoires occupés lors de l'exécution d'un programme.


\end{defi}

\begin{rem}

On distingue la complexité dans le pire des cas, la complexité dans le meilleure des cas, ou la complexité en moyenne. En effet, pour un même algorithme, suivant les données à manipuler, le résultat sera déterminé plus ou moins rapidement. 

Généralement, on s'intéresse au cas le plus défavorable à savoir, la complexité dans le pire des cas. 
\end{rem}

\begin{resultat}
Soit une suite de deux instructions ayant un coût respectif de $C_1$ et $C_2$. Le coût total de la suite d'opération est donc $C=C_1 + C_2$.

Plus généralement, lorsqu'on réalise une itération, le coût total correspond à la somme des différents coûts. En notant $C_i$ le coût de la $i^{\text{ème}}$ suite d'instruction, le coût total de l'itération est donc :
$$
C = \sum\limits_{i=1}^{n}C_i
$$
\end{resultat}

\begin{exemple}
\textit{Calcul de factorielle}

\begin{pseudo}
\begin{algorithm}[H]
\Fonction{
factorielle($n$):\\
\eSi{n=0}{
\Retour{1}
}{
$i\gets1$\\
$res\gets1$\\
\Tq{$i\leq n$}{
$res \gets res \cdot i$ \\
$i\gets i+1$}
\Retour{res}
}}
\end{algorithm}
\end{pseudo}

\textbf{Complexité en mémoire :} lors de l'exécution du porgramme, il sera nécessaire de stocker les variables suivantes : 
\begin{itemize}
\item $n$;
\item $res$;
\item $i$. 
\end{itemize}

\textbf{Complexité en temps :}
On réalise une première comparaison dont on note le coût $C_c$.
 lorsque $n>0$, on réalise à chaque incrément : 
\begin{itemize}
\item une comparaison de coût $C_c$;
\item une multiplication de coût $C_m$;
\item une addition (itération) de coût $C_i$;
\item deux affectations de coût $C_a$;
\end{itemize}
Pour calculer $n!$ la boucle est réitérée $n$ fois. En conséquence, la complexité en temps s'élève à :
$$C = n\cdot(C_c+C_m+C_a+C_i)+C_c$$
\end{exemple}

Il est fréquent que la complexité en temps soit améliorée au prix d'une augmentation de la complexité en espace, et vice-versa.
La complexité dépend notamment :
\begin{itemize}
\item de la puissance de la machine sur laquelle l'algorithme est exécuté;
\item du langage et compilateur / interpréteur utilisé pour coder l'algorithme;
\item du style du programmeur.
\end{itemize}


\begin{rem}
Le coût de la mémoire étant aujourd'hui relativement faible, on cherche en général à améliorer la complexité en temps plutôt que le complexité en mémoire. 
\end{rem}

\subsection{D'autres exemples}
\subsubsection{Recherche d'un maximum}
\begin{exemple}
\textit{Soit une liste de nombre entiers désordonnés. Comment déterminer le plus grand nombre de la liste ?}

Intuitivement, une solution est de parcourir la liste d'élément et de déterminer le plus grand élément par comparaisons successives.


\begin{pseudo}
\begin{algorithm}[H]
\KwData{$tab$ tableau de taille $n$}
$max  \leftarrow -\infty$\\
\For{$i=1$ \KwTo $n$}{
\If{$tab[i]>max$}{
$max  \leftarrow tab[i]$\\
}}
\end{algorithm}
\end{pseudo}

Ainsi, quelle que soit la taille $n$ du tableau, il faudra $n$ itération pour connaître le plus grand élément de la liste. 
\end{exemple}

\subsubsection{Tri d'une liste}

\begin{exemple}
\textbf{Algorithme naïf}

\textit{Soit une liste de nombre entiers désordonnés. Comment les trier par ordre croissant ?}

Une méthode dite naïve pourrait être la suivante : 
\begin{itemize}
\item trouver le plus petit élément du tableau. Notons $min$ son indice;
\item on permute alors le $min$\ieme élément avec le premier élément;
\item ...
\item on trouve le plus petit élément du tableau compris entre l'indice $i$ et $N$;
\item on permute alors le $min$\ieme élément avec le $i$\ieme élément.
\end{itemize}



\begin{pseudo}
\begin{algorithm}[H]
\KwData{$tab$ tableau d'entiers désordonnés de taille $n$}
\KwResult{$tab$ tableau d'entiers ordonnés}
\For{$i=1$ \KwTo $n-1$}{
$ min \leftarrow  i$\\
\For{$j=i+1$ \KwTo $n$}{
\If{$tab[j]<tab[min]$}{
$min  \leftarrow j$\\
}}
$tmp  \leftarrow tab[i]$ \\
$ tab[i] \leftarrow tab[min]$ \\
$ tab[min] \leftarrow tmp$ \\
}

\end{algorithm}
\end{pseudo}

Dans ce cas, pour un tableau de taille $n$, la première boucle sera réalisée $n-1$ fois. Lors de l'itération $i$, la comparaison située dans la seconde boucle sera exécutée $N-(i+1)$ fois. 

En considérant que seule la comparaison à un coût $C$, le coût total s'obtient en comptant le nombre de comparaisons :
\begin{eqnarray*}
(N-(1+1)+1)&+&(N-(2+1)+1)+...+(N-(i+1)+1)+...+(N-(N)+1)+(N-(N+1)+1)\\
&=& (N-1)+(N-2)+...+1 \\
&=& \dfrac{N(N-1)}{2}
\end{eqnarray*}

\end{exemple}

\begin{rem}
Il existe d'autres algorithmes de tris plus performant que l'algorithme présenté ci-dessus : 
\begin{itemize}
\item tri de shell (\textsf{shell sort});
\item tri fusion (\textsf{merge sort});
\item tri rapide (\textsf{quick sort})...
\end{itemize}
\end{rem}

\subsection{Complexité algorithmique}
\begin{defi}
\cite{bournez}
Soient $f$ et $g$ deux fonctions $f,g : \mathbb{N} \rightarrow \mathbb{R}^{+}_{*}$. On note $f(n)=\mathcal{O}(g(n))$ lorsqu'il existe des entiers $c$ et $n_0$ tels que pour tout $n\geq n_0$, 
$$
f(n) \leq c\cdot g(n)
$$

Intuitivement, cela signifie que $f$ est inférieur à $g$ à une constante multiplicative près pour les données suffisamment grandes. 

\end{defi}

\begin{exemple}
Ainsi, l'algorithme de recherche du maximum dans une liste non trié (présenté précédemment) est de complexité $\mathcal{O}(n)$ où $n$ est le nombre d'éléments de la liste. Cet algorithme est proportionnel au nombre d'éléments.

L'algorithme de tri naïf est de complexité $\mathcal{O}(n^2)$. On parle d'algorithme quadratique. Le temps d'exécution devient très grand lorsque le nombre de données et très important. 


Par ordre de complexité croissante on a donc :
\begin{itemize}
\item $\mathcal{O}(1)$ : algorithme s'exécutant en temps constant, quelle que soit la taille des données;
\item $\mathcal{O}(log(n))$ : algorithme rapide (complexité logarithmique) (Exemple : recherche par dichotomie dans un tableau trié);
\item $\mathcal{O}(n)$ : algorithme linéaire;
\item $\mathcal{O}(n\cdot log(n))$ : complexité $n \log n$;
\item $\mathcal{O}(n^2)$ : complexité quadratique;
\item $\mathcal{O}(2^n)$ : complexité exponentielle. 
\end{itemize}
\end{exemple}

\begin{resultat}
Pour une opération ayant un temps d'exécution de $10^{-9}s$, on peut calculer le temps d'exécution en fonction du nombre de données et de la complexité de l'algorithme : 


\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline 
Données & 
$\mathcal{O}(log(n))$ &
$\mathcal{O}(n)$ &
$\mathcal{O}(n\cdot log(n))$ &
$\mathcal{O}(n^2)$ &
$\mathcal{O}(2^n)$ \\
\hline 
100 &     $2\cdot 10^{-9}\; s$ & $0,1\cdot 10^{-6}\; s$ &$0,2\cdot 10^{-6}\; s$ &$10\cdot 10^{-6}\; s$ &$1,26765\cdot 10^{21} \; s$ \\ \hline
1 000 &  $3\cdot 10^{-9}\; s$ & $1\cdot 10^{-6}\; s$ & $3\cdot 10^{-6}\; s$ &$0,001\; s$ & $1,0715\cdot 10^{292}  \; s$\\ \hline
10 000 & $4\cdot 10^{-9}\; s$ & $10\cdot 10^{-6}\; s$ & $40\cdot 10^{-6}\; s$ &$0,1\; s$	 & $+\infty$\\ \hline
\end{tabular}
\end{center}

\end{resultat}

\section{Profiling des algorithmes}

Afin d'évaluer la performance des algorithmes, il existe des fonctionnalités permettant de compter le temps consacré à chacune des fonctions ou à chacune des instructions utilisées dans un programme \url{http://docs.python.org/2/library/profile.html}.

\begin{exemple}

Voici un exemple du crible d'Eratosthène.

\begin{py}
\begin{python}[H]
def crible(n):
    tab=[]
    for i in range(2,n):
        tab.append(i)
    for i in range(0,len(tab)):
        for j in range(len(tab)-1,i,-1):
            if (tab[j]%tab[i]==0):
                tab.remove(tab[j])
    return tab
    
import cProfile            
cProfile.run('crible(10000)')

\end{python}
\end{py}

\textsf{cProfile} renvoie alors le message suivant :

\begin{py}
\begin{python}[H]
 28770 function calls in 1.957 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    1.957    1.957 <string>:1(<module>)
        1    0.420    0.420    1.957    1.957 eratosthene.py:4(crible)
        1    0.000    0.000    1.957    1.957 {built-in method exec}
     9999    0.015    0.000    0.015    0.000 {built-in method len}
     9998    0.016    0.000    0.016    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     8769    1.505    0.000    1.505    0.000 {method 'remove' of 'list' objects}

\end{python}
\end{py}

On alors le bilan du temps passé à effectuer chacune des opérations. Ainsi pour améliorer notablement l'algorithme, le plus intéressant serait d'optimiser la méthode \textsf{remove}.
\end{exemple}




\begin{thebibliography}{2}
\bibitem{denis}{François Denis \url{http://pageperso.lif.univ-mrs.fr/~francois.denis/algoL2/chap1.pdf}}
\bibitem{soyeur}{Alain Soyeur \url{http://asoyeur.free.fr/}}
\bibitem{morain}{François Morain, Cours de l'Ecole Polytechnique, \url{http://www.enseignement.polytechnique.fr/profs/informatique/Francois.Morain/TC/X2004/Poly/www-poly009.html}.}
\bibitem{kerivent}{Renaud Kerivent et Pascal Monasse, La programmation pour ... , Cours de l’École des Ponts ParisTech - 2012/2013 \url{http://imagine.enpc.fr/~monasse/Info}.}
\bibitem{bournez}{Olivier Bournez, Cours INFO 561 de l'Ecole Polytechnique, Algorithmes et programmation, \url{http://www.enseignement.polytechnique.fr/informatique/INF561/uploads/Main/poly-good.pdf}.}
\end{thebibliography}
\end{document}



