\documentclass[10pt,fleqn]{article} % Default font size and left-justified equations
\usepackage[%
    pdftitle={Informatique : Introduction à l'algorithmique},
    pdfauthor={Xavier Pessoles}]{hyperref}

\input{style/new_style}
\input{style/macros_SII}

%\fichetrue
\fichefalse

%\proftrue
\proffalse

%\tdtrue
\tdfalse

\courstrue
%\coursfalse

% -------------------------------------
% Déclaration des titres
% -------------------------------------

\def\discipline{Informatique}
\def\xxtete{Informatique}

\def\classe{PTSI}
\def\xxnumpartie{Partie 2}
\def\xxpartie{Algorithmique \& Programmation}

\def\xxnumchapitre{Chapitre 4}
\def\xxchapitre{\hspace{.12cm} Introduction à la complexité}

\def\xxposongletx{2}
\def\xxposonglettext{1.45}
\def\xxposonglety{22}%19

\def\xxonglet{Part. 2 -- Ch. 4}

\def\xxactivite{Cours}
\def\xxauteur{\textsl{Xavier Pessoles}}

\def\xxcompetences{%
\textsl{%
\textbf{Savoirs et compétences :}
\begin{itemize}[label=\ding{112},font=\color{ocre}] 
\item s'interroger sur l'efficacité algorithmique temporelle.
\end{itemize}
}}

\def\xxfigures{
}%figues de la page de garde

\def\xxpied{%
Partie 2 -- Algorithmique \& Programmation \\
Ch 4 : Introduction à la complexité -- \xxactivite%
}

%---------------------------------------------------------------------------
\begin{document}
\chapterimage{png/Fond_ALG}
\input{style/new_pagegarde}
%---------------------------------------------------------------------------



\section{Mise en évidence du problème}

%\subsection{Premier exemple}
%On introduit les algorithmes de tri suivant : 
%\begin{py}
%\begin{python}
%#Tri par sélection
%def tri_selection(tab):
%    for i in range(0,len(tab)):
%        indice = i
%        for j in range(i+1,len(tab)):
%            if tab[j]<tab[indice]:
%               indice = j
%        tab[i],tab[indice]=tab[indice],tab[i]
%    return tab
%\end{python}
%\end{py}
%
%\begin{py}
%\begin{python}    
%#Tri par insertion
%def tri_insertion(tab):
%    for i in range(1,len(tab)):
%        a=tab[i] 
%        j=i-1    
%        while j>=0 and tab[j]>a:
%            tab[j+1]=tab[j]
%            j=j-1
%        tab[j+1]=a
%    return tab
%\end{python}
%\end{py}
%
%\begin{py}
%\begin{python}
%def shellSort(array):
%     "Shell sort using Shell's (original) gap sequence: n/2, n/4, ..., 1."
%     "http://en.wikibooks.org/wiki/Algorithm_Implementation/Sorting/Shell_sort#Python"
%     gap = len(array) // 2
%     # loop over the gaps
%     while gap > 0:
%         # do the insertion sort
%         for i in range(gap, len(array)):
%             val = array[i]
%             j = i
%             while j >= gap and array[j - gap] > val:
%                 array[j] = array[j - gap]
%                 j -= gap
%             array[j] = val
%         gap //= 2
%\end{python}
%\end{py}
%
%La figure ci-dessous montre le temps en secondes pour trier des tableaux de 1 à 1000 éléments en utilisant les méthodes de tri suivant : 
%\begin{itemize}
%\item tri par sélection;
%\item tri par insertion; 
%\item tri shell;
%\item méthode de tri utilisée par Python.
%\end{itemize}
%
%Le premier graphe montre le temps de calcul et le second une estimation du nombre d'opérations. 
%
%\begin{minipage}[c]{.48\linewidth}
%\begin{center}
%\includegraphics[width=.95\textwidth]{images/figure_1}
%\end{center}
%\end{minipage}\hfill
%\begin{minipage}[c]{.48\linewidth}
%\begin{center}
%\includegraphics[width=.95\textwidth]{images/figure_2}
%\end{center}
%\end{minipage}

%\subsection{Deuxième exemple}
On prend l'exemple de la recherche d'un élément dans une liste : 



\begin{minipage}[c]{.49\linewidth}

\begin{pseudo}
\begin{center}
\begin{tabular}{p{.9\textwidth}}
\hline
\textbf{Algorithme :} Recherche d'un nombre dans une liste triée ou non \\
\hline
\textbf{Données :}
\begin{itemize}
\item \textsf{nb}, int : un entier 
\item \textsf{tab}, liste : une liste d'entiers triés ou non triés
\end{itemize}
\textbf{Résultat :} un booléen : \textsf{Vrai} si le nombre est dans la liste, \textsf{Faux} sinon. \\
\\
\textbf{is\_number\_in\_list}(\textsf{nb},\textsf{tab}) :\\
\hspace{.4cm}\textsf{l} $\leftarrow$ \textbf{longueur}(\textsf{tab}) \\
\hspace{.4cm}\textbf{Pour} \textsf{i} \textbf{allant de} 1 \textbf{à} \textsf{l} \textbf{faire} : \\
\hspace{.8cm} \textbf{Si}  \textsf{tab[i] = nb} \textbf{alors} :\\
\hspace{1.2cm}\textbf{Retourne} \textsf{Vrai} \\
\hspace{.8cm} \textbf{Fin Si} \\
\hspace{.4cm}\textbf{Fin Faire} \\
\hspace{.4cm}\textbf{Retourne} \textsf{Faux} \\
\textbf{Fin fonction} \\
\hline
\end{tabular}
\end{center}
\end{pseudo}
\end{minipage}\hfill
\begin{minipage}[c]{.49\linewidth}
\begin{py}
\begin{python}
def is_number_in_list(nb,tab):
    """Renvoie True si le nombre nb est dans la liste 
    de nombres tab
    Keyword arguments:
      * nb, int -- nombre entier
      * tab, list -- liste de nombres entiers    
    """
    for i in range(len(tab)):
        if tab[i]==nb:
            return True
    return False
\end{python}
\end{py}
\end{minipage}


\begin{exemple}
\`A partir de l'algorithme précédent, évaluer : 
\begin{itemize}
\item le nombre de tour de boucles dans le pire des cas;
\item le nombre de tour de boucles dans le meilleur des cas.
\end{itemize}
\end{exemple}

\begin{py}
\begin{python}
def is_number_in_list_dicho(nb,tab):
    """ 
    Recherche d'un nombre par dichotomie dans un tableau trié. 
    Renvoie l'index si le nombre nb est dans la liste de nombres tab.
    Renvoie None sinon.
    Keyword arguments:
    nb,int -- nombre entier
    tab,list -- liste de nombres entiers triés
    """
    g, d = 0, len(tab)-1
    while g <= d:
        m = (g + d) // 2
        if tab[m] == nb:
            return m
        if tab[m] < nb:
            g = m+1
        else:
            d = m-1
    return None
\end{python}
\end{py}



\begin{center}
\includegraphics[width=.95\textwidth]{images/figure_5}

\textit{Évolution du nombre d'opérations pour rechercher un nombre dans une liste de 1 à 1000 nombres}
\end{center}



\section{Complexité des algorithmes}

\subsection{Présentation}
Il existe souvent plusieurs façons de programmer un algorithme. Si le nombre d'opérations à effectuer est peu important et les données d'entrée de l'algorithme sont de faibles tailles, le choix de la solution importe peu. En revanche, lorsque le nombre d'opérations et la taille des données d'entrée deviennent importants, deux paramètres deviennent déterminants : le temps d'exécution et l'occupation mémoire. 


\begin{defi}
\textbf{Complexité en temps}

La complexité en temps donne le nombre d'opérations effectuées lors de l'exécution d'un programme. On appelle $C_o$ le coût en temps d'une opération $o$.

\textbf{Complexité en mémoire (ou en espace)}

La complexité en mémoire donne le nombre d'emplacements mémoires occupés lors de l'exécution d'un programme.


\end{defi}

\begin{rem}

On distingue la complexité dans le pire des cas, la complexité dans le meilleure des cas, ou la complexité en moyenne. En effet, pour un même algorithme, suivant les données à manipuler, le résultat sera déterminé plus ou moins rapidement. 

Généralement, on s'intéresse au cas le plus défavorable à savoir, la complexité dans le pire des cas. 
\end{rem}

%\begin{resultat}
%Soit une suite de deux instructions ayant un coût respectif de $C_1$ et $C_2$. Le coût total de la suite d'opération est donc $C=C_1 + C_2$.
%
%Plus généralement, lorsqu'on réalise une itération, le coût total correspond à la somme des différents coûts. En notant $C_i$ le coût de la $i^{\text{ème}}$ suite d'instruction, le coût total de l'itération est donc :
%$$
%C = \sum\limits_{i=1}^{n}C_i
%$$
%\end{resultat}

\subsection{Coût temporel d'un algorithme et d'une opération}
\begin{minipage}[c]{.47\linewidth}
\begin{resultat}
On considère que le coût élémentaire $C_e$ correspond au coût d'une affectation, d'une comparaison ou de l'évaluation d'une opération arithmétique. 
\end{resultat}
\end{minipage}\hfill
\begin{minipage}[c]{.47\linewidth}
\begin{exemple}
Chacune de ces 3 opérations expressions ont le même coût temporel $C_e$:
\begin{py}
\begin{python}
>>> a=20
>>> a<=100
>>> a+a
\end{python}
\end{py}
\end{exemple}
\end{minipage}

\vspace{.5cm}

\begin{minipage}[c]{.47\linewidth}
\begin{resultat}
Pour une séquence de deux instructions de coûts respectifs $C_1$ et $C_2$, le coût total est de la séquence est de $C_1 + C_2$.
\end{resultat}
\end{minipage}\hfill
\begin{minipage}[c]{.47\linewidth}
\begin{exemple}
\begin{py}
\begin{python}
>>> a=20
>>> print(a)
\end{python}
\end{py}
Le coût temporel correspond à l'addition du coût élémentaire de l'affectation ajouté au coût de l'affichage.
\end{exemple}
\end{minipage}

\vspace{.5cm}

\begin{minipage}[c]{.47\linewidth}
\begin{resultat}
Le coût d'un test \textsf{if test : inst\_1 else : inst\_2 } est inférieur ou égal au maximum du coût de l'instruction 1 et du coût de l'instruction 2 additionné au coût du test (coût élémentaire). 
\end{resultat}
\end{minipage}\hfill
\begin{minipage}[c]{.47\linewidth}
\begin{exemple}
Soit le programme suivant (sans application réelle) :
\begin{py}
\begin{python}
>>>    if x<0 :
               x=x+1
               x=x+2
           else :
               x=x+1
\end{python}
\end{py}

La comparaison a un coût élémentaire $C_e$. Dans le <<~pire~>> des cas, on réalise deux additions et deux affectations. 
Le coût temporel total est est donc $C_e + 4C_e = 5C_e$.
\end{exemple}
\end{minipage}

\vspace{.5cm}

\begin{minipage}[c]{.47\linewidth}
\begin{resultat}
Le coût d'une boucle \textsf{for i in range(n) : inst}  est égal à : $n$ fois le coût de l'instruction \textsf{inst} si elle est indépendante de la valeur de $i$.
\end{resultat}
\end{minipage}\hfill
\begin{minipage}[c]{.47\linewidth}
\begin{exemple}

\begin{py}
\begin{python}
>>> for i in range(20) : print(i)
\end{python}
\end{py}
Si on note $C_p$ le coût de l'affichage, le coût total est de $20 C_p$.
\end{exemple}
\end{minipage}

\vspace{.5cm}

%\begin{minipage}[c]{.47\linewidth}
\begin{resultat}
Soit la boucle \textsf{while cond : inst}, la condition \textsf{cond} faisant intervenir un variant de boucle. Il est donc possible de connaître le nombre $n$ d'itérations de la boucle. 
Le coût de la boucle est donc égal à n fois le coût de l'instruction \textsf{inst}.
\end{resultat}
%\end{minipage}\hfill
%\begin{minipage}[c]{.47\linewidth}
%\begin{exemple}

%\begin{py}
%\begin{python}

%\end{python}
%\end{py}
%\end{exemple}
%\end{minipage}


\subsection{Exemple}

\begin{exemple}
\textit{Calcul de factorielle}

\begin{pseudo}
\begin{algorithm}[H]
\Fonction{
factorielle($n$):\\
\eSi{n=0}{
\Retour{1}
}{
$i\gets1$\\
$res\gets1$\\
\Tq{$i\leq n$}{
$res \gets res \cdot i$ \\
$i\gets i+1$}
\Retour{res}
}}
\end{algorithm}
\end{pseudo}

\textbf{Complexité en mémoire :} lors de l'exécution du programme, il sera nécessaire de stocker les variables suivantes : 
\begin{itemize}
\item $n$;
\item $res$;
\item $i$. 
\end{itemize}

\textbf{Complexité en temps :}
La première comparaison a un coût élémentaire $C_e$.

Pour $n=0$  le coût du retour est $C_r$.

Pour $n \neq 0$ :
\begin{itemize}
\item les deux affectations ont un coût respectif $C_e$;
\item la boucle tant que sera réalisée $n$ fois. Pour chaque itération, 
\begin{itemize}
\item la multiplication ainsi que l'affectation ont un chacun un coût $C_e$;
\item l'incrémentation et l'affectation ont chacun un coût $C_e$;
\end{itemize}
\item le coût du retour est $C_r$.
\end{itemize}
En conséquence, la complexité en temps s'élève à :
$$C_T(n) = C_e + \max\left( C_r;  C_e + C_e + n\left( 4C_e\right) + C_r\right)$$

Ainsi $C_T(n) = C_e (3 + 4n)  + C_r$ et $C_T(n)  \underset{+\infty}{\sim} 4C_e n$ lorsque $n$ tend vers l'infini. On parle d'une complexité algorithmique linéaire, notée $\mathcal{O}(n)$.

\end{exemple}



Il est fréquent que la complexité en temps soit améliorée au prix d'une augmentation de la complexité en espace, et vice-versa.
La complexité dépend notamment :
\begin{itemize}
\item de la puissance de la machine sur laquelle l'algorithme est exécuté;
\item du langage et compilateur / interpréteur utilisé pour coder l'algorithme;
\item du style du programmeur.
\end{itemize}


\begin{rem}
Le coût de la mémoire étant aujourd'hui relativement faible, on cherche en général à améliorer la complexité en temps plutôt que le complexité en mémoire. 
\end{rem}

\subsection{D'autres exemples}
\subsubsection{Recherche d'un maximum}
\begin{exemple}
\textit{Soit une liste de nombre entiers désordonnés. Comment déterminer le plus grand nombre de la liste ?}

Intuitivement, une solution est de parcourir la liste d'élément et de déterminer le plus grand élément par comparaisons successives.


\begin{pseudo}
\begin{algorithm}[H]
\KwData{$tab$ tableau de taille $n$}
$max  \leftarrow -\infty$\\
\For{$i=1$ \KwTo $n$}{
\If{$tab[i]>max$}{
$max  \leftarrow tab[i]$\\
}}
\end{algorithm}
\end{pseudo}

Dans ce cas, le coût temporel est :
$C_T(n) = C_e + n\left(2 C_e \right)$. Ici encore, la complexité de cet algorithme est linéaire car $C_T(n) \underset{+\infty}{\sim} 2 C_e n$.
\end{exemple}

\subsubsection{Tri d'une liste}

\begin{exemple}
\textbf{Algorithme naïf}

\textit{Soit une liste de nombre entiers désordonnés. Comment les trier par ordre croissant ?}

Une méthode dite naïve pourrait être la suivante : 
\begin{itemize}
\item trouver le plus petit élément du tableau. Notons $min$ son indice;
\item on permute alors le $min$\ieme élément avec le premier élément;
\item ...
\item on trouve le plus petit élément du tableau compris entre l'indice $i$ et $N$;
\item on permute alors le $min$\ieme élément avec le $i$\ieme élément.
\end{itemize}



\begin{pseudo}
\begin{algorithm}[H]
\KwData{$tab$ tableau d'entiers désordonnés de taille $n$}
\KwResult{$tab$ tableau d'entiers ordonnés}
\For{$i=1$ \KwTo $n-1$}{
$ min \leftarrow  i$\\
\For{$j=i+1$ \KwTo $n$}{
\If{$tab[j]<tab[min]$}{
$min  \leftarrow j$\\
}}
$tmp  \leftarrow tab[i]$ \\
$ tab[i] \leftarrow tab[min]$ \\
$ tab[min] \leftarrow tmp$ \\
}

\end{algorithm}
\end{pseudo}

Ici les bornes de la boucle imbriquée dépendent de l'indice $i$. Ainsi :
\begin{itemize}
\item au rang $1$, $C_1 = C_e + \left(n-1\right)\left( 2 C_e\right) + 3 C_e$;
\item au rang $2$, $C_2 = C_e + \left(n-2\right)\left( 2 C_e\right) + 3 C_e$;
\item au rang $i$, $C_i = C_e + \left(n-i)\right)\left( 2 C_e\right) + 3 C_e$.
\end{itemize}

Le coût temporel peut donc s'exprimer ainsi : 
\begin{eqnarray*}
C_T(n) &=& \sum\limits_{i=0}^{n} \left(Ce + (n-i)\left( 2 C_e\right) + 3 C_e \right) = C_e\sum\limits_{i=0}^{n} \left( 1+2n-2i + 3 \right) \\
&=&C_e\sum\limits_{i=0}^{n} \left( 4+2n-2i  \right) =  C_e \left( 4n+2n^2 -  2\dfrac{n(n+1)}{2}\right) = C_e\left( 3n+n^2\right)
%C_e \left( 5n + n^2  \right)
\end{eqnarray*}

Dans ce cas, $C_T(n)\sim C_e n^2$. On parle de complexité quadratique. Lorsque la taille du tableau double, le temps de calcul est multiplié par 4.

\end{exemple}

%\begin{rem}
%Il existe d'autres algorithmes de tris plus performant que l'algorithme présenté ci-dessus : 
%\begin{itemize}
%\item tri de shell (\textsf{shell sort});
%\item tri fusion (\textsf{merge sort});
%\item tri rapide (\textsf{quick sort})...
%\end{itemize}
%\end{rem}

\subsubsection{Diviser pour régner -- recherche dichotomique}
\begin{exemple}
\begin{py}
\begin{python}
def recherche_dichotomique(x, a):
    g, d = 0, len(a)-1
    while g <= d:
        m = (g + d) // 2
        if a[m] == x:
            return m
        elif a[m] < x:
            g = m+1
        else:
            d = m-1
    return None
\end{python}
\end{py}
On peut montrer que la suite $d-g$ décroit strictement (car $d$ décroit et $g$ croit).
Dans ce cas, la difficulté consiste en déterminer le nombre de fois que sera exécutée la boucle \textsf{while}. On note $C_w = C_e + \max\left(C_e + C_r ; 2 C_e + 2 C_e; 3 C_e + C_e \right) = C_e + \max\left(C_e + C_r ; 4 C_e  \right)$ le coût d'une itération de la boucle \textsf{while}.

Au cours de l'algorithme, on va devoir diviser en 2 la taille le tableau jusqu'à ce qu'on trouve (ou pas) l'élément recherché. On cherche donc combien de fois $m$ on peut diviser par 2 la taille du tableau $n$ :
$$
\dfrac{n}{2^m} \geq 1 \Longleftrightarrow n \geq 2^m \Longleftrightarrow \ln(n)\geq m \ln(2) $$
On parlera ici de complexité logarithmique.

%Au cours de l'algorithme, on va devoir diviser la quantité $g+d$ par 2 tant que $g$ est inférieur à $d$. On cherche donc $n$ tel que $g>d$. On considère que la borne $d$ est fixe. On note $p$ la taille du tableau donc $d=p \; \forall n\in\mathbb{N}$ et $g_0=1$.
%Exprimons la suite décrite par les valeurs de $g$ :
%\begin{eqnarray*}
%g_n &= &m_n + 1 = \dfrac{g_{n-1}+p}{2}+1 =\dfrac{1}{2}g_{n-1} + \dfrac{p}{2} + 1\\
%g_{n-1} &=& \dfrac{1}{2}g_{n-2} + \dfrac{p}{2} + 1 \\
%g_n &=& \dfrac{1}{2}\left( \dfrac{1}{2}g_{n-2} + \dfrac{p}{2} + 1 \right) + \dfrac{p}{2} + 1
% = \dfrac{1}{2}\cdot \dfrac{1}{2}g_{n-2} + \dfrac{1}{2}\cdot \dfrac{p}{2} +  \dfrac{1}{2} + \dfrac{p}{2} + 1
%\end{eqnarray*}
%
%On peut donc faire la conjecture que :
%$$
%g_n = 1+ \dfrac{1}{2^n}g_0 + \sum\limits_{j=1}^{n}\dfrac{1+p}{2^n} 
%=  1+ \left( 1+p \right)\sum\limits_{j=1}^{n}\dfrac{1}{2^n} 
%$$
%
%Au rang 1, $g_1= 1+ \dfrac{1}{2}+ \dfrac{1+p}{2} =  \dfrac{3+p}{2}$ 


%On note $k$ la kième étape. 

%Si :
%\begin{itemize}
%\item le tableau contient $1$ élément, la boucle \textsf{while} est exécutée 1 fois;
%\item le tableau contient $2$ élément, la boucle \textsf{while} est exécutée 2 fois;
%\item le tableau contient $4$ élément, la boucle \textsf{while} est exécutée 2 fois.
%\end{itemize}

\end{exemple}

\subsection{Complexité algorithmique}
\begin{defi}
\cite{Bournez}
Soient $f$ et $g$ deux fonctions $f,g : \mathbb{N} \rightarrow \mathbb{R}^{+}_{*}$. On note $f(n)=\mathcal{O}(g(n))$ lorsqu'il existe $c\in\mathbb{R}^+$ et $n_0\in\mathbb{N}$ tels que pour tout $n\geq n_0$, 
$$
f(n) \leq c\cdot g(n)
$$

Intuitivement, cela signifie que $f$ est inférieur à $g$ à une constante multiplicative près pour les données suffisamment grandes. 

\end{defi}

\begin{exemple}
Ainsi, l'algorithme de recherche du maximum dans une liste non trié (présenté précédemment) est de complexité $\mathcal{O}(n)$ où $n$ est le nombre d'éléments de la liste. Cet algorithme est proportionnel au nombre d'éléments.

L'algorithme de tri naïf est de complexité $\mathcal{O}(n^2)$. On parle d'algorithme quadratique. Le temps d'exécution devient très grand lorsque le nombre de données et très important. 


Par ordre de complexité croissante on a donc :
\begin{itemize}
\item $\mathcal{O}(1)$ : algorithme s'exécutant en temps constant, quelle que soit la taille des données;
\item $\mathcal{O}(log(n))$ : algorithme rapide (complexité logarithmique) (Exemple : recherche par dichotomie dans un tableau trié);
\item $\mathcal{O}(n)$ : algorithme linéaire;
\item $\mathcal{O}(n\cdot log(n))$ : complexité $n \log n$;
\item $\mathcal{O}(n^2)$ : complexité quadratique;
\item $\mathcal{O}(2^n)$ : complexité exponentielle. 
\end{itemize}
\end{exemple}

\begin{exemple}
\begin{itemize}
\item Le coût temporel de l'algorithme pour calculer une factorielle est $4C_e n$ et on a  $4C_e n \leq c n$. La complexité de l'algorithme est en $\mathcal{O}(n)$.
\item Le coût temporel de l'algorithme de recherche d'un maximum est $2C_e n$ et on a  $2C_e n \leq c n$. La complexité de l'algorithme est en $\mathcal{O}(n)$.
\item Le coût temporel de l'algorithme de tri dans une liste en utilisant l'algorithme naïf est $C_e n^2$ et on a  $C_e n^2 \leq c n^2$.  La complexité de l'algorithme est en $\mathcal{O}(n^2)$.
\item Le coût temporel de l'algorithme de recherche dichotomique est de l'ordre de $C_w \dfrac{\ln(n)}{\ln(2)}$ et on a  $C_w \dfrac{\ln(n)}{\ln(2)} \leq c \ln (n)$. La complexité de l'algorithme est en $\mathcal{O}(\log (n))$.
\end{itemize}
\end{exemple}


\begin{resultat}
Pour une opération ayant un temps d'exécution de $10^{-9}s$, on peut calculer le temps d'exécution en fonction du nombre de données et de la complexité de l'algorithme : 

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline 
Données & 
$\mathcal{O}(log(n))$ &
$\mathcal{O}(n)$ &
$\mathcal{O}(n\cdot log(n))$ &
$\mathcal{O}(n^2)$ &
$\mathcal{O}(2^n)$ \\
\hline 
100 &     $2\cdot 10^{-9}\; s$ & $0,1\cdot 10^{-6}\; s$ &$0,2\cdot 10^{-6}\; s$ &$10\cdot 10^{-6}\; s$ &$1,26765\cdot 10^{21} \; s$ \\ \hline
1 000 &  $3\cdot 10^{-9}\; s$ & $1\cdot 10^{-6}\; s$ & $3\cdot 10^{-6}\; s$ &$0,001\; s$ & $1,0715\cdot 10^{292}  \; s$\\ \hline
10 000 & $4\cdot 10^{-9}\; s$ & $10\cdot 10^{-6}\; s$ & $40\cdot 10^{-6}\; s$ &$0,1\; s$	 & $+\infty$\\ \hline
\end{tabular}
\end{center}

\end{resultat}

\section{Profiling des algorithmes}

Afin d'évaluer la performance des algorithmes, il existe des fonctionnalités permettant de compter le temps consacré à chacune des fonctions ou à chacune des instructions utilisées dans un programme \url{http://docs.python.org/2/library/profile.html}.

\begin{exemple}

Voici un exemple du crible d'Eratosthène.

\begin{py}
\begin{python}[H]
def crible(n):
    tab=[] 
    for i in range(2,n):
        tab.append(i)
    # Liste en comprehension tab=[x for x in range(2,n)]
    for i in range(0,len(tab)):
        for j in range(len(tab)-1,i,-1):
            if (tab[j]%tab[i]==0):
                tab.remove(tab[j])
    return tab
    
import cProfile            
cProfile.run('crible(10000)')

\end{python}
\end{py}

\textsf{cProfile} renvoie alors le message suivant :

\begin{py}
\begin{python}[H]
 28770 function calls in 1.957 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    1.957    1.957 <string>:1(<module>)
        1    0.420    0.420    1.957    1.957 eratosthene.py:4(crible)
        1    0.000    0.000    1.957    1.957 {built-in method exec}
     9999    0.015    0.000    0.015    0.000 {built-in method len}
     9998    0.016    0.000    0.016    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     8769    1.505    0.000    1.505    0.000 {method 'remove' of 'list' objects}

\end{python}
\end{py}

On alors le bilan du temps passé à effectuer chacune des opérations. Ainsi pour améliorer notablement l'algorithme, le plus intéressant serait d'optimiser la méthode \textsf{remove}.
\end{exemple}




\begin{thebibliography}{2}
\bibitem{denis}{François Denis \url{http://pageperso.lif.univ-mrs.fr/~francois.denis/algoL2/chap1.pdf}}
\bibitem{soyeur}{Alain Soyeur \url{http://asoyeur.free.fr/}}
\bibitem{morain}{François Morain, Cours de l'Ecole Polytechnique, \url{http://www.enseignement.polytechnique.fr/profs/informatique/Francois.Morain/TC/X2004/Poly/www-poly009.html}.}
\bibitem{kerivent}{Renaud Kerivent et Pascal Monasse, La programmation pour ... , Cours de l’École des Ponts ParisTech - 2012/2013 \url{http://imagine.enpc.fr/~monasse/Info}.}
\bibitem{Bournez}{Olivier Bournez, Cours INFO 561 de l'Ecole Polytechnique, Algorithmes et programmation, \url{http://www.enseignement.polytechnique.fr/informatique/INF561/uploads/Main/poly-good.pdf}.}
\bibitem{wack}{Wack et Al., \textit{L'informatique pour tous en classes préparatoires aux grandes écoles}, Editions Eyrolles.}
\end{thebibliography}
\end{document}


 